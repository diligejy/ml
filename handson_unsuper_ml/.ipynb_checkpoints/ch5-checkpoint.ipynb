{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "'''메인 라이브러리'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time\n",
    "import pickle, gzip\n",
    "\n",
    "'''시각화 관련 라이브러리'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''데이터 준비 및 모델 평가 관련 라이브러리'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "'''알고리즘 관련 라이브러리'''\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import fastcluster\n",
    "from scipy.cluster.hierarchy import dendrogram, cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 로드\n",
    "current_path = os.getcwd()\n",
    "file = os.path.sep.join(['', 'datasets', 'mnist_data', 'mnist.pkl.gz'])\n",
    "\n",
    "f = gzip.open(current_path+file, 'rb')\n",
    "train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "X_train, y_train = train_set[0], train_set[1]\n",
    "X_validation, y_validation = validation_set[0], validation_set[1]\n",
    "X_test, y_test = test_set[0], test_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋으로부터 판다스 데이터 프레임 만들기\n",
    "train_index = range(0,len(X_train))\n",
    "validation_index = range(len(X_train), \\\n",
    "                         len(X_train)+len(X_validation))\n",
    "test_index = range(len(X_train)+len(X_validation), \\\n",
    "                   len(X_train)+len(X_validation)+len(X_test))\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train,index=train_index)\n",
    "y_train = pd.Series(data=y_train,index=train_index)\n",
    "\n",
    "X_validation = pd.DataFrame(data=X_validation,index=validation_index)\n",
    "y_validation = pd.Series(data=y_validation,index=validation_index)\n",
    "\n",
    "X_test = pd.DataFrame(data=X_test,index=test_index)\n",
    "y_test = pd.Series(data=y_test,index=test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주성분 분석\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 784\n",
    "whiten = False\n",
    "random_state = 2018\n",
    "\n",
    "pca = PCA(n_components=n_components, whiten=whiten, \\\n",
    "          random_state=random_state)\n",
    "\n",
    "X_train_PCA = pca.fit_transform(X_train)\n",
    "X_train_PCA = pd.DataFrame(data=X_train_PCA, index=train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-평균 - 군집 수에 따른 관성\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 10\n",
    "n_init = 10\n",
    "max_iter = 300\n",
    "tol = 0.0001\n",
    "random_state = 2018\n",
    "n_jobs = 2\n",
    "\n",
    "kMeans_inertia = pd.DataFrame(data=[],index=range(2,21), \\\n",
    "                              columns=['inertia'])\n",
    "for n_clusters in range(2,21):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n",
    "                max_iter=max_iter, tol=tol, random_state=random_state, \\\n",
    "                n_jobs=n_jobs)\n",
    "\n",
    "    cutoff = 99\n",
    "    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n",
    "    kMeans_inertia.loc[n_clusters] = kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeans_inertia.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeCluster(clusterDF, labelsDF):\n",
    "    countByCluster = \\\n",
    "        pd.DataFrame(data=clusterDF['cluster'].value_counts())\n",
    "    countByCluster.reset_index(inplace=True,drop=False)\n",
    "    countByCluster.columns = ['cluster','clusterCount']\n",
    "        \n",
    "    preds = pd.concat([labelsDF,clusterDF], axis=1)\n",
    "    preds.columns = ['trueLabel','cluster']\n",
    "    \n",
    "    countByLabel = pd.DataFrame(data=preds.groupby('trueLabel').count())\n",
    "        \n",
    "    countMostFreq = \\\n",
    "        pd.DataFrame(data=preds.groupby('cluster').agg( \\\n",
    "                        lambda x:x.value_counts().iloc[0]))\n",
    "    countMostFreq.reset_index(inplace=True,drop=False)\n",
    "    countMostFreq.columns = ['cluster','countMostFrequent']\n",
    "    \n",
    "    accuracyDF = countMostFreq.merge(countByCluster, \\\n",
    "                        left_on=\"cluster\",right_on=\"cluster\")\n",
    "    overallAccuracy = accuracyDF.countMostFrequent.sum()/ \\\n",
    "                        accuracyDF.clusterCount.sum()\n",
    "    \n",
    "    accuracyByLabel = accuracyDF.countMostFrequent/ \\\n",
    "                        accuracyDF.clusterCount\n",
    "    \n",
    "    return countByCluster, countByLabel, countMostFreq, \\\n",
    "            accuracyDF, overallAccuracy, accuracyByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-평균 - 군집 수에 따른 정확도\n",
    "\n",
    "n_clusters = 5\n",
    "n_init = 10\n",
    "max_iter = 300\n",
    "tol = 0.0001\n",
    "random_state = 2018\n",
    "n_jobs = 2\n",
    "\n",
    "kMeans_inertia = \\\n",
    "    pd.DataFrame(data=[],index=range(2,21),columns=['inertia'])\n",
    "overallAccuracy_kMeansDF = \\\n",
    "    pd.DataFrame(data=[],index=range(2,21),columns=['overallAccuracy'])\n",
    "\n",
    "for n_clusters in range(2,21):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n",
    "                max_iter=max_iter, tol=tol, random_state=random_state, \\\n",
    "                n_jobs=n_jobs)\n",
    "\n",
    "    cutoff = 99\n",
    "    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n",
    "    kMeans_inertia.loc[n_clusters] = kmeans.inertia_\n",
    "    X_train_kmeansClustered = kmeans.predict(X_train_PCA.loc[:,0:cutoff])\n",
    "    X_train_kmeansClustered = \\\n",
    "        pd.DataFrame(data=X_train_kmeansClustered, index=X_train.index, \\\n",
    "                     columns=['cluster'])\n",
    "    \n",
    "    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, \\\n",
    "        accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans \\\n",
    "        = analyzeCluster(X_train_kmeansClustered, y_train)\n",
    "    \n",
    "    overallAccuracy_kMeansDF.loc[n_clusters] = overallAccuracy_kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallAccuracy_kMeansDF.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyByLabel_kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-평균 - 주성분 수에 따른 정확도\n",
    "\n",
    "n_clusters = 20\n",
    "n_init = 10\n",
    "max_iter = 300\n",
    "tol = 0.0001\n",
    "random_state = 2018\n",
    "n_jobs = 2\n",
    "\n",
    "kMeans_inertia = pd.DataFrame(data=[],index=[9, 49, 99, 199, \\\n",
    "                    299, 399, 499, 599, 699, 783],columns=['inertia'])\n",
    "\n",
    "overallAccuracy_kMeansDF = pd.DataFrame(data=[],index=[9, 49, \\\n",
    "                    99, 199, 299, 399, 499, 599, 699, 783], \\\n",
    "                    columns=['overallAccuracy'])\n",
    "\n",
    "for cutoffNumber in [9, 49, 99, 199, 299, 399, 499, 599, 699, 783]:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n",
    "                max_iter=max_iter, tol=tol, random_state=random_state, \\\n",
    "                n_jobs=n_jobs)\n",
    "\n",
    "    cutoff = cutoffNumber\n",
    "    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n",
    "    kMeans_inertia.loc[cutoff] = kmeans.inertia_\n",
    "    X_train_kmeansClustered = kmeans.predict(X_train_PCA.loc[:,0:cutoff])\n",
    "    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, \\\n",
    "                                index=X_train.index, columns=['cluster'])\n",
    "    \n",
    "    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, \\\n",
    "        accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans \\\n",
    "        = analyzeCluster(X_train_kmeansClustered, y_train)\n",
    "    \n",
    "    overallAccuracy_kMeansDF.loc[cutoff] = overallAccuracy_kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallAccuracy_kMeansDF.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-평균 - 주성분 수에 따른 정확도\n",
    "# 원본 MNIST 데이터 셋(PCA를 통한 축소가 없는)\n",
    "\n",
    "n_clusters = 20\n",
    "n_init = 10\n",
    "max_iter = 300\n",
    "tol = 0.0001\n",
    "random_state = 2018\n",
    "n_jobs = 2\n",
    "\n",
    "kMeans_inertia = pd.DataFrame(data=[],index=[9, 49, 99, 199, \\\n",
    "                    299, 399, 499, 599, 699, 783],columns=['inertia'])\n",
    "\n",
    "overallAccuracy_kMeansDF = pd.DataFrame(data=[],index=[9, 49, \\\n",
    "                    99, 199, 299, 399, 499, 599, 699, 783], \\\n",
    "                    columns=['overallAccuracy'])\n",
    "\n",
    "for cutoffNumber in [9, 49, 99, 199, 299, 399, 499, 599, 699, 783]:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, \\\n",
    "                max_iter=max_iter, tol=tol, random_state=random_state, \\\n",
    "                n_jobs=n_jobs)\n",
    "\n",
    "    cutoff = cutoffNumber\n",
    "    kmeans.fit(X_train.loc[:,0:cutoff])\n",
    "    kMeans_inertia.loc[cutoff] = kmeans.inertia_\n",
    "    X_train_kmeansClustered = kmeans.predict(X_train.loc[:,0:cutoff])\n",
    "    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, \\\n",
    "                                index=X_train.index, columns=['cluster'])\n",
    "    \n",
    "    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, \\\n",
    "        accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans \\\n",
    "        = analyzeCluster(X_train_kmeansClustered, y_train)\n",
    "    \n",
    "    overallAccuracy_kMeansDF.loc[cutoff] = overallAccuracy_kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallAccuracy_kMeansDF.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계층적 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcluster\n",
    "from scipy.cluster.hierarchy import dendrogram, cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "cutoff = 99\n",
    "Z = fastcluster.linkage_vector(X_train_PCA.loc[:,0:cutoff], \\\n",
    "                               method='ward', metric='euclidean')\n",
    "Z_dataFrame = pd.DataFrame(data=Z, \\\n",
    "    columns=['clusterOne','clusterTwo','distance','newClusterSize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_dataFrame.iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_dataFrame.iloc[49980:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "distance_threshold = 160\n",
    "clusters = fcluster(Z, distance_threshold, criterion='distance')\n",
    "X_train_hierClustered = \\\n",
    "    pd.DataFrame(data=clusters,index=X_train_PCA.index,columns=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of distinct clusters: \", \\\n",
    "      len(X_train_hierClustered['cluster'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countByCluster_hierClust, countByLabel_hierClust, \\\n",
    "    countMostFreq_hierClust, accuracyDF_hierClust, \\\n",
    "    overallAccuracy_hierClust, accuracyByLabel_hierClust \\\n",
    "    = analyzeCluster(X_train_hierClustered, y_train)\n",
    "\n",
    "print(\"Overall accuracy from hierarchical clustering: \", \\\n",
    "      overallAccuracy_hierClust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy by cluster for hierarchical clustering\")\n",
    "accuracyByLabel_hierClust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "eps = 3\n",
    "min_samples = 5\n",
    "leaf_size = 30\n",
    "n_jobs = 4\n",
    "\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples, leaf_size=leaf_size, \n",
    "            n_jobs=n_jobs)\n",
    "\n",
    "cutoff = 99\n",
    "X_train_PCA_dbscanClustered = db.fit_predict(X_train_PCA.loc[:,0:cutoff])\n",
    "X_train_PCA_dbscanClustered = \\\n",
    "    pd.DataFrame(data=X_train_PCA_dbscanClustered, index=X_train.index, \\\n",
    "                 columns=['cluster'])\n",
    "\n",
    "countByCluster_dbscan, countByLabel_dbscan, countMostFreq_dbscan, \\\n",
    "    accuracyDF_dbscan, overallAccuracy_dbscan, accuracyByLabel_dbscan \\\n",
    "    = analyzeCluster(X_train_PCA_dbscanClustered, y_train)\n",
    "\n",
    "overallAccuracy_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall accuracy from DBSCAN: \",overallAccuracy_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster results for DBSCAN\")\n",
    "countByCluster_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "min_cluster_size = 30\n",
    "min_samples = None\n",
    "alpha = 1.0\n",
    "cluster_selection_method = 'eom'\n",
    "\n",
    "hdb = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, \\\n",
    "        min_samples=min_samples, alpha=alpha, \\\n",
    "        cluster_selection_method=cluster_selection_method)\n",
    "\n",
    "cutoff = 10\n",
    "X_train_PCA_hdbscanClustered = \\\n",
    "    hdb.fit_predict(X_train_PCA.loc[:,0:cutoff])\n",
    "\n",
    "X_train_PCA_hdbscanClustered = \\\n",
    "    pd.DataFrame(data=X_train_PCA_hdbscanClustered, \\\n",
    "    index=X_train.index, columns=['cluster'])\n",
    "\n",
    "countByCluster_hdbscan, countByLabel_hdbscan, \\\n",
    "    countMostFreq_hdbscan, accuracyDF_hdbscan, \\\n",
    "    overallAccuracy_hdbscan, accuracyByLabel_hdbscan \\\n",
    "    = analyzeCluster(X_train_PCA_hdbscanClustered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall accuracy from HDBSCAN: \",overallAccuracy_hdbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster results for HDBSCAN\")\n",
    "countByCluster_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_un)",
   "language": "python",
   "name": "conda_un"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
